{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER4_Classification_Consilium_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbfMIGC-B8J3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGJHJ8ZsUpk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data_classification()\n",
        "  # to be added as we get inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2McWlzTWQQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xavier_initializer(x, y):\n",
        "\n",
        "  def inxavier(x, y):\n",
        "    return torch.Tensor(x, y).uniform(-1, 1)*math.sqrt(6./(x+y))\n",
        "\n",
        "  for i in range(epochs):\n",
        "    a = inxavier(x, y)\n",
        "    xavier = tanh(a @ xavier)\n",
        "\n",
        "  return xavier  \n",
        "\n",
        "  # It can be done using the Glorot Uniform class too as shown in the next block of code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGxAXA7WDBaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xavier_initializer_Glorot(m):\n",
        "  def make_variables(k, initializer):\n",
        "    return (tf.Variable(initializer(shape=[k, k], dtype=tf.float32)))\n",
        "  xavier = make_variables(m, tf.initializers.GlorotUniform())\n",
        "  return xavier\n",
        "\n",
        "  # I have yet to see which Xavier function to utilise, though this one is preferred."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L6CzAc6fAQ7",
        "colab_type": "text"
      },
      "source": [
        "I thought of defining two CNN models, one according to the paper and one which has been derived from a few other papers, just to be able to compare accuracies and have two separate simple classification models in hand. They are not too complex, they just have different layers and kernels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb1Dp8_RfnEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_model(input_shape=(32,32,28), num_classes=6):\n",
        "\n",
        "  model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(32, (5, 5), activation='relu', input_shape=(32, 32, 28)),\n",
        "                                      tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
        "                                      tf.keras.layers.Conv2D(64, (5, 5), activation='relu'),\n",
        "                                      tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
        "                                      tf.keras.layers.Flatten(),\n",
        "                                      tf.keras.layers.Dropout(0.25),\n",
        "                                      tf.keras.layers.Dense(6, activation=tf.nn.softmax)])\n",
        "  \n",
        "  return model\n",
        "  \n",
        "  # This is the simple CNN model as was designed in the paper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqAA7bAuiP1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_model_custom(input_shape=(32,32,28), num_classes=6):\n",
        "\n",
        "  model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(6, (5, 5), activation='relu', input_shape=(32, 32, 28)),\n",
        "                                      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "                                      tf.keras.layers.Conv2D(16, (5, 5), activation='relu'),\n",
        "                                      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "                                      tf.keras.layers.Conv2D(120, (5, 5), activation='relu'),\n",
        "                                      tf.keras.layers.Dropout(0.25),\n",
        "                                      tf.keras.layers.Flatten(),\n",
        "                                      tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dropout(0.4),\n",
        "                                      tf.keras.layers.Dense(6, activation=tf.nn.softmax)])\n",
        "  \n",
        "  return model\n",
        "  \n",
        "  # This is the second CNN model as is built on the culmination of one other paper which yielded fantastic results for JAFFE dataset and one image classification stackoverflow link"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx-HYBlKV1LS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This block is to be able to use the momentum optimizer while compiling CNN\n",
        "\n",
        "tf.compat.v1.train.MomentumOptimizer(\n",
        "    learning_rate, momentum, use_locking=False, name='momentum', use_nesterov=True\n",
        ")\n",
        "model.compile(optimizer = momentum(lr),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Momentum optimizer.\n",
        "# I have yet to discover how to use Xavier Initializer with Momentum Optimizer, if there is a possibility that it yields better results.\n",
        "# I am also looking into building a custom optimizer if that promises better accuracies\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7pSH6DleDur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(lr=lr),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Adam optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
